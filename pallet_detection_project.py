# -*- coding: utf-8 -*-
"""Pallet Detection_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LbOsjXz0K4QrssflOlTDVSf1xenVrrPF

1. ⚙️ Preprocessing Dataset (Roboflow format)
Assumes images and labels are exported in YOLO format from Roboflow.
"""

!pip install ultralytics

from ultralytics import YOLO
import os
import shutil

# Roboflow Export: Ensure structure is
# ├── datasets/
# │   └── pallet_detection/
# │       ├── train/
# │       │   ├── images/
# │       │   └── labels/
# │       ├── valid/
# │       │   ├── images/
# │       │   └── labels/
# │       └── data.yaml

dataset_path = '/content/drive/MyDrive/Pallet Detection image/Pallets Detection.v1i.yolov8'  # Update path accordingly

# Show sample images
import cv2
import matplotlib.pyplot as plt

img_sample_path = os.path.join(dataset_path, 'train/images')
sample_imgs = os.listdir(img_sample_path)[:3]

for img in sample_imgs:
    image = cv2.imread(os.path.join(img_sample_path, img))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title(f'Sample: {img}')
    plt.axis('off')
    plt.show()

"""2. 🚀 Training YOLO Models"""

# Train YOLO models
model_variants = {
    "YOLOv8n": "yolov8n.pt",
    "YOLOv8m": "yolov8m.pt",
    "YOLOv8l": "yolov8l.pt",
    "YOLOv9c": "yolov9c.pt",     # Custom path if added
    "YOLOv11n": "yolov11n.pt"    # Custom path if added
}

results = {}

for name, weights in model_variants.items():
    print(f"\nTraining: {name}")
    model = YOLO(weights)
    result = model.train(
        data=f"{dataset_path}/data.yaml",
        epochs=50,
        imgsz=640,
        batch=16,
        project="pallet_yolo_results",
        name=name,
        verbose=False
    )
    results[name] = result

"""3. 📊 Evaluation Code (Accuracy, Precision, Inference Time)"""

from ultralytics.utils.benchmarks import benchmark

evaluation_summary = []

for name in model_variants:
    model_path = f"pallet_yolo_results/{name}/weights/best.pt"
    model = YOLO(model_path)

    # Evaluate
    metrics = model.val()
    # Benchmark Inference Time
    speed_result = benchmark(model=model, imgsz=640, half=False, device=0)

    evaluation_summary.append({
        "Model": name,
        "mAP50": round(metrics.box.map50, 4),
        "mAP50-95": round(metrics.box.map, 4),
        "Precision": round(metrics.box.precision, 4),
        "Recall": round(metrics.box.recall, 4),
        "FPS": round(speed_result['FPS'], 2),
        "Inference Time (ms)": round(1000 / speed_result['FPS'], 2)
    })

"""4. 📋 Final Results Summary Table"""

import pandas as pd

summary_df = pd.DataFrame(evaluation_summary)
print(summary_df.sort_values(by="mAP50-95", ascending=False))